---
title: "Practical Machine Learning"
author: "Shannon Holgate"
date: "Sunday, August 23, 2015"
output: html_document
---
### Background
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

### Goal
Use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participant. Predict the manner in which the participant completed the excercise, classified using the `classe` variable.

### Cleaning the Data

The data was loaded into R dataframes from the csv format. All empty fields were replaced with NA.
The dataframes were then insvestigated to see which columns were made redundant because of the missing values. The columns which were made up of only missing values were removed from further processing.

```{r}
train <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
test <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))

train <- train[, colSums(is.na(train)) == 0] 
test <- test[, colSums(is.na(test)) == 0] 
```

Upon further inspection of the data it was noted that the first 7 columns contained information on the user and not the excercise. These columns were removed as they would not assist in building a prediction model.

```{r}
train <- train[ , -(1:7)]
test <- test[ , -(1:7)]
```

### Partitioning the Data

The datasets are now partitioned to make use of cross validation

```{r}
library(caret)
trainPart <- createDataPartition(y = train$classe, p = 0.7, list = F)
training <- train[trainPart,]
testing <- train[-trainPart,]
```

### Building the Model

The Random Forests method is used to build up the prediction model. The model is then tested against our test set to build a confusion matrix

```{r}
control <- trainControl(method = "cv", 5)
rfModel <- train(classe ~ ., method = "rf", data = training, trControl = control, ntree = 150)
rfModel
predictions <- predict(rfModel, testing)
confusionMatrix(testing$classe, predictions)
```

The sample of error is then calculated to evaluate the performance of this model.

```{r}
cm <- table(testing$classe, predictions)
1 - (sum(diag(cm))/ length(predictions))
```

The confusion matrix has shown that the random forests model created is satisfactory. The model is now used to predict the classe variable from the initial test set.

```{r}
answers <- predict(rfModel, test)
answers
```

### Submission 

```{r}
pml_write_files = function(x) {
     n = length(x)
     for(i in 1:n) {
         filename = paste0("problem_id_", i, ".txt")
         write.table(x[i], file=filename, quote=FALSE, row.names=FALSE, col.names=FALSE)
     }
 }

pml_write_files(answers)
```
